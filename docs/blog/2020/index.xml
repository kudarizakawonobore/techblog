<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>下り坂を昇るブログ</title>
    <link>https://kudarizakawonobore.github.io/techblog/blog/2020/</link>
    <description>Recent content on 下り坂を昇るブログ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Tue, 07 Apr 2020 19:39:10 +0900</lastBuildDate>
    
	<atom:link href="https://kudarizakawonobore.github.io/techblog/blog/2020/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>クラウドエンジニアのいない組織でクラウド導入を検討するためのガイドライン</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/07-cloud-agreement/</link>
      <pubDate>Tue, 07 Apr 2020 19:39:10 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/07-cloud-agreement/</guid>
      <description>動機 コロナの影響で、世の中、リモート、在宅中心の流れになっているが、同業他社が続々とリモート化を進めている中、インフラ整備がおいついていないなどの理由から、なかなか踏み切れない組織がある。
会議のみ、突貫で Zoom や WebEX を導入して難を逃れている組織もあるようだが、これはアリとキリギリスの問題で、ファイルのコラボレーションや、情報資産の保護、認証基盤の準備など、リモートを想定して作られていないものをいきなり移行することは難しい。（技術的な難しさより、むしろマインドシフトの難しさ） なんだかんだで結局出社してしまっている企業も多いようだ。
そんな組織で、自ら問題意識を持って、リモートの推進を進めるべく、クラウドベースのシステムを導入していこうと思っている立場の人がちらほら、自分の周りに増え始めた。
が、いかんせん、専門的な知識がなかったり、相談先がなかったり、保守派の意見に対抗できなかったりと、様々な障壁にぶち当たっているようだ。
自分は、業務内外でクラウドを使うようになって数年の間に、Amazon,Microsoft,Google(GSuite/Office365含む) の3社クラウドサービスすべてにおいてそれぞれ1回以上、契約作業、管理業務に携わった、割とレアな経験があるので、自身の経験や苦労を踏まえて、 推進を進めている人の力になれればと。
想定している状況 50人以上の組織で、エンジニアがあまり多くない会社や学校、医療機関といった組織で、専門知識がない人が、クラウド導入、リモート導入を進めることになった、という状況を想定。
50人、という数字の意図は、「一個人の立替経費で月額の支払いをまかなうのが苦しくなる」という意味。給料の体系によってはもうちょっと前後するかもしれない。
想定しているクラウドは、自身の経験から、 Office365, もしくは GSuite のどちらか、またはその両方。 がっつり開発やら分析やらをしていく企業であれば、AWS, GCP, Azure も検討対象に上がるが、エンジニアでない人がこれらの選定をすることはまれだと推察できるので、除外。
契約までの流れを理解する まずは、全容を理解するために、契約までの大まかな流れを理解することが重要。 組織の意思決定のスピードによっては、数カ月単位の長丁場になるが、自分がいまどのぐらいの位置にいるのか、次に何が起こるかわかっていると、先手先手で動けるので、安心できる。
契約に限らず、どんなプロジェクトにも言えることだが、適切なタイミングで、適切な人数で、適切な範囲の検討を行わないと、話が発散して空中分解してしまうので、それぞれどのタイミングで誰を巻き込むべきかはシミュレーションしておくとよい。
全体の流れ 普段、契約関係をまとめるような業種の方からすると釈迦に説法かもしれないが、クラウドの契約は下記のような流れで話が進み、数回の意思決定を行いながら運用開始にこぎつける。
意思決定その１（有識者の選定）
↓
各社営業さんに相談
↓
トライアル
↓
意思決定その２（サービスの決定）
↓
リセラーさんと相談
↓
意思決定その３（管理者の決定）
意思決定その４（ドメインの決定）
意思決定その５（サポート契約の決定）
↓
リセラーさんと契約
↓
意思決定その６（セキュリティポリシーの決定）
↓
少人数で運用開始
↓
課題確認
↓
運用開始
契約に係る作業自体は、半日もあれば終了するが、初めての場合は1か月以上の長丁場を想定した方がいい。
なお、長丁場になる原因の9割は、組織内の調整である。 以下、組織内の調整をスムーズに進めるためのコツを紹介しながら、それぞれのフェーズでやるべきことを説明していく。
意思決定その１（有識者の選定） 一番大事な作業。
先にも書いた通り、推進自体は組織内の調整がほとんどなので、有識者でなくても何とかなるが、選定や、契約時に出てくる用語の理解、リスクの管理など、とにもかくにも、有識者がいないことには、不安がぬぐい切れないし、なかなか前に進まないことも多い。
意思決定のスピードによってはそれなりに長丁場になるので、いるのであれば組織内から有識者を募る。組織内で協力が得られそうになければ、手っ取り早く外部から募ってもいい。 (外部から募る場合は謝礼を用意して、最後までコミットしてもらうようにする。)
各社営業さんに相談 GSuite であれば、Google さん、 Office365 であれば Microsoft さんの営業に相談する。 ここで、契約に関する流れの詳細について教えてくれる。</description>
    </item>
    
    <item>
      <title>自作 SPA アプリケーションを Azure AD / Open ID Connect を使って保護する</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/06-azure-oauth2/</link>
      <pubDate>Sat, 04 Apr 2020 11:36:27 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/06-azure-oauth2/</guid>
      <description>動機 クラウド上に、一般公開したくない便利ツールや組織内ツールを配置するときなどは、不特定多数の人間に見られないように、何らかの制限を加えることになる。
業務拠点が1か所に限定される場合は、IPアドレス制限で事足りてしまうこともあるが、リモートワークやら、他企業との連携など、多様な業務に対応するのは難しく、あるタイミングから、認証の基盤が必要になってくる。
簡易的でいいのであれば、basic 認証でもいいのだが、パスワードが乱立すると管理が煩雑になる。クラウド上にアップロードしたコンテンツを、組織内 AD のアカウントで閲覧制限できるようになると、運用も楽になって安心である。
GCP (Google アカウント）でやる場合 GCP でやる場合は割と簡単で、 App Engine 上にコンテンツを作成し、 Identity Aware Proxy で保護してやれば、管理者がホワイトリストで一覧化した Google アカウント のみに閲覧を許可することができる。
しかし、アカウント管理が AzureAD ベースになっている組織で、非公式に Google アカウントを発行すると、退職/退プロ者 のアカウント削除漏れが発生する可能性が出てきて、インシデントにつながりやすい。(人事部の運用も大変になる)
Azure AD のアカウントを GSuite に統合する方法もあるが、 GSuite の管理者権限が必要だったり、組織全体を巻き込んだ大がかりな意思決定が必要になるっぽい。
そのため、あくまでAzure のリソースや、AD の設定をいじるだけで、MSアカウントによる 認証を実現する方法を考えてみたい。
ゴール Blob 上にホストした SPA(Vue.js で実装) を、ホワイトリストに登録した AD ユーザー のみが閲覧できるようになれば OK。
この時、ホワイトリストに登録するのは、テナント外の人間も含む。（パートナー企業とか、子会社、親会社への閲覧も想定）
もともと閲覧できていたユーザーを 即時 閲覧不可にするのは、いったん考えないものとする。
準備 やることは、大きく分けて、下記の2つ
  Azure AD のアプリケーションを作成し、ユーザーを割り当てる
  Client アプリを msal で保護する
  Azure AD の アプリケーションの作成 Azure Portal から、 Azure Active Directory -&amp;gt; アプリの登録 と進む。</description>
    </item>
    
    <item>
      <title>GCP AppEngine のデプロイに Cloud Build の権限が必要になったっぽい</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/04-appengine-deploy/</link>
      <pubDate>Sun, 08 Mar 2020 03:56:39 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/04-appengine-deploy/</guid>
      <description>概要 自分の勉強用のメモ書きなど、一般公開はしたくないものの、インターネット上から一部の 人に見せたいようなドキュメントは、普段 AppEngine × IdentityAwareProxy で認証付きサイトとして限定公開している。
デプロイを手動でやると面倒なので、BitBucket の BuildPipeline から自動でデプロイするように設定しているのだが、2週間ぐらい前に突然失敗するようになっていた。
対象となる人 gcloud app deploy コマンド実行時、下記のように、Failed to create cloud build: Permission denied. と表示される人。
結論 題名の通り。デプロイに使っている サービスアカウントから、CloudBuild を実行できるようにしてあげたらデプロイできるようになる。
以下、手順。
API の有効化 プロジェクトで普段 CloudBuild を使っていない場合は、API を有効化してやる。 プロジェクトオーナー権限でデプロイしている人は、この手順だけでOKのはず。
APIとサービス から API の有効化 ボタンを押下して、API を有効化する。
当該サービスアカウントに CloudBuild の実行権限を付与する サービスアカウントをきっちり管理している人は、最低限の権限しか与えていないはずなので、 CloudBuild サービスアカウント ロールを付与してやる必要がある。
IAM と管理 -&amp;gt; IAM から、デプロイに使っているサービスアカウントを選択して、 下記のように、Cloud Build サービスアカウント の役割を追加する。
最終的に、下記の権限がついていればOK
  AppEngine 管理者
  Cloud Build サービスアカウント
  ストレージオブジェクト管理者</description>
    </item>
    
    <item>
      <title>Raspberry Pi で QR コードリーダーからプログラムを動かす</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/02_qrcode/</link>
      <pubDate>Thu, 20 Feb 2020 23:09:00 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/02_qrcode/</guid>
      <description>概要 市販のQRコードリーダーを起動契機にして、何かしらの処理を行うデバイスを作りたいときの実装メモ。
環境 Raspberry Pi 3 OS: Raspbian Python: 3.6.5
知っておきたいこと USB タイプの QR コードリーダーや、バーコードリーダーは、キーボードと同様の入力デバイスとして扱うことができる。
QRコードリーダーを RaspberryPi に差した状態で、QR コードを Read する（＝デコードする）と、市販の QRコードリーダーがテキスト入力として PC にイベントを送ってくる。 なので、単に値を解読したいだけなら、テキストエディタを開いた状態で、QRコードを読み込んであげるだけでよい。
自作のアプリから、デコードした値を処理したいなら、キーボードのイベントをListen し、Enterキーが押されたのを起動契機に処理を実行するプログラムを書いてあげればよい。
候補 Python でキーボードの入力を取得するためのライブラリはいくつかあるが、今回は keyboard を採用した。
下記は、不採用になったものを含めたキーボードの入力を取得するためのライブラリ。
pynput(不採用) キーボードやマウスの入力を Listen できるライブラリ。 keyboard 同様、文字列として入力を受け付けられるが、 SSH 経由でバックグラウンド実行させることができなさそうなので、不採用。
envdev(不採用) pynput と異なり、SSH 経由でバックグラウンド実行させられる他、デバイスを指定することができる。 一方で、発生したイベントがコード文字列(KEY_A や KEY_B など）になってしまうためコードを文字列に戻してやる処理が必要になる。
keyboard(採用) バックグラウンドで実行でき、文字列をわりと簡単に処理できるので、採用。
インストール pip で keyboard をインストールする
pip install keyboard実装 import keyboardimport timeqr = &amp;#34;&amp;#34;def key_press(key):global qrif key.</description>
    </item>
    
    <item>
      <title>iPhone のカメラで撮影した画像を直接PC に取り込む</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/01-capture/</link>
      <pubDate>Sun, 16 Feb 2020 20:58:40 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/01-capture/</guid>
      <description>動機 Jupyter/OpenCV などで画像処理のロジックを書いていると、主に閾値調整やフィルタリング処理が、テスト用に使っている画像に局所最適化されてしまうことがままある。
ある程度ロジックを書いた後、複数の写真を撮ってテストできれば、調整もたやすく、コードの汎用性も上がるはず。
一方で、iPhone の画像は、何枚か撮影して、メールや iCloud, Google Photo などを使えばインターネット越しで共有できるが、そうすると、ファイル名がわかりづらかったり、Zip を解凍したりと、いくつか面倒な作業が発生する。
せっかく手元に iPhone があるのだから、直接取り込んであげられれば、作業もはかどりそうなものである。
結論 今回は外部のツールを使うだけなので、いたってシンプル。 iVCam という iPhone のアプリを使うだけ。
準備 スマホ側と、PC 側にアプリをインストールするだけ。
スマホ側 iVcam で検索。 無償版は、ファイル内にロゴが映りこむため、有償版を使った方が良い。
PC 版 こちらのサイトからダウンロードして、インストールする。 https://www.e2esoft.com/ivcam/
実行するとき PC,スマホの両方でアプリを起動している状態で、かつ、同一ネットワーク上にいると、iPhone のカメラに映っている映像がそのままPC でキャプチャ、保存できる。
撮影した画像は、アプリ側で任意のディレクトリに保存できる。 機械学習用に、アノテーション付きでファイルを管理したい場合は、撮影するタイミングでディレクトリ分けができるので、画像の管理がかなりラクになる。
利点 無線ネットワーク越しにファイルを取り込めるので、例えば、有線のWebカメラのように物理的な範囲の制限がないのが魅力。 例えば、スマホを3脚に固定しておいて、定点で複数枚写真を撮るような要件にも対応できる。
欠点 解像度はそんなに高くない模様。そのため、OCR に使おうと思うと、いまいち文字が認識しづらかったりする。</description>
    </item>
    
    <item>
      <title>はてなブログを卒業して GitHubPages × Hugo にしてみた</title>
      <link>https://kudarizakawonobore.github.io/techblog/blog/2020/00-hugo/</link>
      <pubDate>Mon, 20 Jan 2020 23:30:27 +0900</pubDate>
      
      <guid>https://kudarizakawonobore.github.io/techblog/blog/2020/00-hugo/</guid>
      <description>動機 いままで個人ブログの作成を はてなブログでやっていたが、下記のような課題を感じていた
エディタ・コピペ問題 普段、あらゆるエディタのキーバインドを Vim 仕様にしているせいで、ブログの記述も Vim キーバインドでやりたい。
はてなブログの サイト上のエディタ では 私の知る限り、 Vim キーバインドで記述するのは難しい。 そのため、ローカルで Markdown 形式でファイルを作成し、コピペする方式になるのだが、 そうすると下記のような問題にぶち当たる。
キャプチャ管理問題 キャプチャを貼り付けるときは、ブログが管理しているディレクトリのリンクを記述することになる。 ローカルで確認しにくいうえ、アップロードのたびにサイトに行ったり、「ここにキャプチャ」的な記述を残したりするのが面倒。
Preview 煩わしい問題 記事を書き終わった後、ローカルで記述した記事を公開用に調整（主に見た目）するときに、何度も Preview → 書き直し を繰り返すことになる。 これが、ページ遷移が何度も発生するため、かなり煩わしいことに加え、上記の問題と相まって、サイト → ローカル へのコピペも必要になったりして、デグレが発生する確率も上がる。
ローカルでサクサクと、公開用の見た目を調整して、ワンコマンドで公開、なんてことを目指したいところ。
実際、はてなブログ用のCSS やらをローカルに落としてきて、疑似的に開発環境を構築することもできるのだろうが、最近は静的サイトジェネレータと、GitHubPages を使えば、簡単に上記課題を解決できるので思い切って移行してみることにした。
Hugo 静的サイトジェネレータを複数試して比較してみた結果、Hexo と Hugo が候補に残った。
Hexo は Node ベースの静的サイトジェネレータで、Hugo と引けを取らない機能の充実ぶりと、GithubPages に公開するまでの手順が非常に簡単なのが魅力だったが、LiveReload の速さが決め手で、Hugo を選択することにした。
Hugo とは、静的サイトジェネレータの1種で、 Go によって動く。
インストール方法 前提 下記はインストール済みである前提
 Go Git  インストール手順（簡単） 下記リンクから、exe をダウンロードして、Pathを通すだけでOK
https://github.com/gohugoio/hugo/releases
公式サイトには、　Chocolatey を使ってインストールする方法が記述されているので、 お好きな方で。
各種 コマンド サイトを作成 hugo new site &amp;lt;サイトを管理するディレクトリ名&amp;gt;上記コマンドを実行すると、ディレクトリに必要なファイルが生成される。</description>
    </item>
    
  </channel>
</rss>